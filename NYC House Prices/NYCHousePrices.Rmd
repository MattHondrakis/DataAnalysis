---
title: "NYC House Prices"
author: "Matthew"
date: "4/24/2022"
output: 
  github_document:
    toc: true
editor_options: 
  chunk_output_type: console
---


# Introduction

This project was inspired by a course taken by a friend of mine for his masters. I believe the data came from Kaggle but I am not certain. The task was to fit a model to predict NYC Housing prices but I wanted to take this opportunity and fit different models and compare the results. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, dpi = 600)
library(tidyverse)
library(skimr)
library(patchwork)
library(broom)
library(tidymodels)
library(rnaturalearth)
library(rnaturalearthdata)
library(splines)
theme_set(theme_bw())
```


```{r}
house <- read_csv("C:/Users/Matthew Hondrakis/OneDrive/Documents/data_lat_long2.csv")
house <- house[,-1]
```

# Explore and Clean
```{r}
skim(house)

house <- 
  house %>% rename_with(tolower) %>% 
  rename_with( ~ gsub(" information", "", .x)) %>% 
  rename_with( ~ gsub(" ", "_", .x))
```

Cleaning column names to make typing them easier moving forward.

```{r}
head(house[,1:4])
head(house[,5:8])
head(house[,9:12])
head(house[,13:16])
head(house[,17:20])
head(house[,21:24])
head(house[,25:27])
```


```{r}
house <- house %>% 
  mutate(across(c(bath:sqft, tax:total_cost), ~ parse_number(.x)))

house <- house %>% 
  rename(by_car = commute) %>% 
  mutate(by_car = parse_number(by_car))
```

Extracting the number portion of the numeric variables and editing the *commute* column. It only contains information on car travel, therefore it will be rename to *by_car* and the number portion will be extracted from it as well. 

```{r}
house <- house %>% 
  mutate(type = sub(",.*","", home_details))
```

By removing everything after the first comma in the *home_details* variable, we are left with a variable containing the type of property. This variable will be named *type*. 
Time to take a closer look at the numeric variables, excluding longitude (*lon*) and latitude (*lat*).

```{r}
house %>% 
  keep(is.numeric) %>% 
  select(-lon, -lat) %>% 
  gather() %>% 
  ggplot(aes(value)) + geom_histogram() + facet_wrap(~key, scales = "free")
```

Most numeric variables appear to be lognormally distributed.

```{r}
house %>% 
  keep(is.numeric) %>% 
  select(-lon, -lat) %>% 
  pivot_longer(-price) %>% 
  ggplot(aes(value, price)) + geom_point() +
  scale_y_log10() + scale_x_log10() +
  facet_wrap(~name)
```

When plotting price against the numeric variables, a bimodal distribution appears. This may be explored further using a knn model.

```{r}
house %>% 
  select_if(is.numeric) %>% 
  select(-lon, -lat) %>% 
  drop_na() %>% 
  pivot_longer(-price) %>% 
  group_by(name) %>% 
  summarize(corr = cor(price, value)) %>% 
  arrange(-abs(corr))
```

There does not seem to be a linear relationship between price and the other numeric variables.

```{r}
house %>% 
  keep(is.numeric) %>% 
  select(-lon, -lat) %>% 
  drop_na() %>% 
  mutate(across(everything(), ~log(.x), .names = "log_{.col}")) %>% 
  pivot_longer(-log_price) %>% 
  group_by(name) %>% 
  summarize(corr = cor(log_price, value)) %>% 
  arrange(-abs(corr)) %>% 
  filter(name != "price" & !is.na(corr))
```

Log(price) improves the linear correlation with respect to the numeric variables. A simple linear regression model will now be fit for log(price) vs each numeric variable.

```{r}
tidy_model <- house %>% 
  select_if(is.numeric) %>% 
  select(-lon, -lat) %>% 
  drop_na() %>% 
  pivot_longer(-price) %>% 
  nest(-name) %>% 
  mutate(mod = map(data, ~ lm(log(price) ~ value, .x)),
         tidy = map(mod, broom::tidy)) %>% 
  unnest(tidy)
```


```{r}
tidy_model %>% 
  filter(term == "value") %>% 
  arrange(-abs(estimate))
```

## Checking correlated variables
```{r}
gplot <- function(x){
  (house %>% 
    filter(!is.na({{x}}), !is.na(price)) %>% 
    ggplot(aes({{x}}, price, group = {{x}})) + geom_boxplot() + scale_y_log10()) +
  (house %>% 
     filter(!is.na({{x}}), !is.na(price)) %>% 
     group_by({{x}}) %>% 
     summarize(m = mean(price, na.rm = TRUE)) %>% 
     ggplot(aes({{x}}, m)) + geom_line() + scale_y_log10())
}

gplot(bath)
gplot(bed)
gplot(assessment_year)
```


```{r}
house %>% 
  filter(price != 0, !is.na(price)) %>% 
  mutate(price = price/1e3,
         type = fct_lump(type, 7),
         type = fct_reorder(type, price, median)) %>% 
  ggplot(aes(price, type)) + geom_boxplot() +
  scale_x_log10(labels = scales::comma) + labs(x = "", title = "Price in thousands") +
  theme(plot.margin = margin(10,50,10,0))
```

The type of property seems to be significant, lets explore this further.

## Plots of Price by numerics using Type to color
```{r}
gplot2 <- function(x){
  house %>% 
    ggplot(aes({{x}}, price, color = fct_lump(type, 6))) + 
    geom_point() +
    scale_x_log10() + scale_y_log10()
}
(gplot2(tax) +
gplot2(total_cost) +
gplot2(land_assessment_cost)) /
(gplot2(sqft) +
gplot2(improvement_cost)) + plot_layout(guides = 'collect')
```

The bimodal distribution is finally explained by this new variable. Type of property accounts for this separation, Coop vs (Single & Multi Family, Townhouse and Condo).

# Model
## Preprocess
```{r}
house <- house %>% 
  mutate(type_mod = fct_lump(type, 6))

house_mod <- house %>% 
  select(price, tax, total_cost, sqft, land_assessment_cost,
         improvement_cost, type_mod, bath, bed, address) %>% 
  drop_na() %>% 
  filter_if(is.numeric, all_vars(. > 0))

house_mod %>% 
  keep(is.numeric) %>% 
  cor()
```


```{r}
house_mod %>% 
  keep(is.numeric) %>% 
  pivot_longer(-tax) %>% 
  ggplot(aes(tax, value)) + geom_point() +
  facet_wrap(~name, scales = "free")
```

There is a lot of correlation between tax and the other numeric variables, as can be seen by the graphs above.

```{r}
house_mod %>% 
  ggplot(aes(bath, price)) + geom_point() + scale_y_log10() +
  geom_smooth()
```

There are some outliers in the number of baths that don't seem reliable. Many of the apartments with 15 or more baths may come from faulty data (some addresses were checked as well).

```{r}
updated_model <- 
  lm(log(price) ~ (log(sqft) + log(tax) + bath) * type_mod, 
   house_mod)

anova(updated_model)
summary(updated_model)

(augment(updated_model) %>% 
  ggplot(aes(`log(price)`,.fitted, color = type_mod)) + 
  geom_point(alpha = 0.5) + geom_abline()) /
(augment(updated_model) %>% 
  mutate(residual = .fitted - `log(price)`) %>% 
  ggplot(aes(.fitted, residual, color = type_mod)) + 
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0)) + plot_layout(guides = "collect")

hist(residuals(updated_model))
```

The diagnostic plots don't show any irregularities. 

## Tidymodels

### Set up and data split
```{r}
set.seed(123)
house_split <- initial_split(house_mod %>% 
                               mutate(price = log(price),
                                      tax = log(tax),
                                      sqft = log(sqft),
                                      bath = log(bath), 
                             strata = bath))
house_test <- testing(house_split)
house_train <- training(house_split)
```


### Model creating and fit
```{r}
mod <- linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("lm")
rec <- recipe(price ~ tax + sqft + 
                     bath + type_mod, house_train) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_interact(terms = ~ starts_with("type"):all_predictors())
wkfl <- workflow() %>% 
  add_model(mod) %>% 
  add_recipe(rec)
wkfl_fit <- fit(wkfl, house_train)
```


### Analysis
```{r}
house_res <- 
  house_test %>% 
  bind_cols(predict(wkfl_fit, house_test))
```


```{r}
(house_res %>%
  mutate(residuals = price - .pred) %>% 
  ggplot(aes(.pred, residuals, color = type_mod)) + 
  geom_point(alpha = 0.5) + geom_hline(yintercept = 0)) /
(house_res %>%  
  ggplot(aes(.pred, price, color = type_mod)) + 
  geom_point(alpha = 0.5) + geom_abline()) + plot_layout(guide = "collect")
```


```{r}
three_metrics <- metric_set(rsq, rmse, mae)

joined_metrics <- three_metrics(augment(updated_model) %>% 
      rename(price = `log(price)`),
    price, .fitted) %>% 
  mutate(model = "1") %>% 
  bind_rows(three_metrics(house_res, price, .pred) %>% 
              mutate(model = "2"))

joined_metrics %>% arrange(desc(.metric))
```


```{r}
joined_metrics %>% 
  ggplot(aes(.estimate, .metric, fill = model)) +
  geom_col(position = "dodge") +
  labs(title = "Base R model (1) vs Tidymodels (2)",
       caption = "Comparison is not equal; the fit methods were done differently. \n
       Did not separate a training/testing dataset for the first model")
```

The original base R model just barely outperforms the tidymodels model. The only difference between the 2 is that the tidymodels model was trained on a subset of the data, while the original was trained on the whole dataset.

```{r}
house <- house %>% 
  mutate(zip_code = str_sub(address, - 5, - 1))

x <- house %>% 
  filter(!is.na(price)) %>% 
  group_by(zip_code) %>% 
  summarize(m = median(price)) %>% 
  arrange(-m) %>% 
  head(20) %>% 
  pull(zip_code)
y <- house %>% 
  filter(!is.na(price)) %>% 
  group_by(zip_code) %>% 
  summarize(m = median(price)) %>% 
  arrange(-m) %>% 
  tail(20) %>% 
  pull(zip_code)
  
house %>% 
  select(zip_code, price) %>% group_by(zip_code) %>% 
  filter(!is.na(price), zip_code %in% c(x,y)) %>% 
  group_by(zip_code) %>% 
  ggplot(aes(price, fct_reorder(zip_code, price, median))) + geom_boxplot() +
  scale_x_log10() + labs(y = "", title = "House Prices in NYC by zipcode", x = "Price (log10 scale)")
```

## No Taxes!
```{r}
wkfl2 <- workflow() %>% 
  add_model(mod) %>% 
  add_recipe(recipe(price ~ sqft + 
                     bath + type_mod, house_train) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_interact(terms = ~ starts_with("type"):all_predictors()))

wkfl_fit2 <- fit(wkfl2, house_train)
```


```{r}
house_res2 <- house_test %>%
  bind_cols(predict(wkfl_fit2, house_test))
  
all_metrics <- joined_metrics %>% 
  bind_rows(three_metrics(house_res2, price, .pred) %>% 
              mutate(model = "3"))
```


```{r}
all_metrics %>% 
  ggplot(aes(.estimate, .metric, fill = model)) +
  geom_col(position = "dodge")

all_metrics %>% 
  arrange(desc(.metric), -.estimate)
```


# Borough?
```{r}
house %>% 
  mutate(borough = case_when(
    str_detect(address, "New York") ~ "New York",
    str_detect(address, "Brooklyn") ~ "Brooklyn",
    str_detect(address, "Queens") ~ "Queens",
    str_detect(address, "Bronx") ~ "Bronx",
    str_detect(address, "Staten Island") ~ "Staten Island"
  )) %>% 
  filter(!is.na(borough), !is.na(price)) %>% 
  ggplot(aes(price, borough)) + geom_boxplot() + scale_x_log10()
```



## Don't miss the forrest for the trees
```{r}
house_mod <- house_mod %>%
  mutate(zip_code = str_sub(address, -5, -1))

house_mod %>% 
  ggplot(aes(tax, price, color = zip_code)) + geom_point() +
  theme(legend.position = "none") + scale_x_log10() +
  scale_y_log10()

house_mod2 <- house_mod %>% 
  mutate(zip_code = fct_lump(zip_code, prop = 0.003))
```


```{r}
set.seed(123)
split2 <- initial_split(house_mod2 %>% 
                               mutate(price = log(price),
                                      tax = log(tax),
                                      sqft = log(sqft),
                                      zip_code = factor(zip_code),
                                      bath = factor(bath)),
                        strata = zip_code)


train2 <- training(split2)
test2 <- testing(split2)
```


```{r}
modrf <- rand_forest() %>% 
  set_mode("regression") %>% 
  set_engine("ranger")


recrf <- recipe(price ~ sqft + type_mod + zip_code, train2) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_interact(terms = ~ starts_with("type"):all_predictors())

wkflrf <- workflow() %>% 
  add_model(modrf) %>% 
  add_recipe(recrf)
```


```{r}
wkflrf_fit <- fit(wkfl2, train2)

house_res2 <- 
  test2 %>% 
  bind_cols(predict(wkflrf_fit, test2))

all_metrics_rf <- all_metrics %>% 
  bind_rows(three_metrics(house_res2, price, .pred) %>% 
              mutate(model = "4"))

all_metrics_rf %>% 
  arrange(desc(.metric), -.estimate)
```


```{r}
all_metrics_rf %>% 
  ggplot(aes(.estimate, .metric, fill = fct_reorder(model, .estimate, max, .desc = TRUE))) +
  geom_col(position = "dodge") + 
  labs(title = "All 4 Models", 
       subtitle = "Base R lm (Red), TM lm (Green), TM no tax lm (Blue), Random Forrest (Purple)") +
  theme(legend.position = "none") + scale_x_continuous(breaks = seq(0.3,0.7,0.05))
```



# Just let Gam figure it out
```{r}
library(mgcv)
library(gratia)
set.seed(10)
gam_data <- house %>% 
  select(price, tax, sqft, bath, lon, lat, type_mod) %>% 
  mutate(price = log(price)) %>% 
  drop_na()

gam_split <- initial_split(gam_data, strata = type_mod)

gam_train <- training(gam_split)
gam_test <- testing(gam_split)

gam_mod <- gam(price ~ 
                 s(sqft, by = type_mod) + 
                 s(bath, by = type_mod) + 
                 s(lon, lat), 
               gaussian, gam_train, method = 'REML')

summary(gam_mod)

appraise(gam_mod)

draw(gam_mod, select = smooths(gam_mod)[1:6])

draw(gam_mod, select = smooths(gam_mod)[7:12])

draw(gam_mod, select = smooths(gam_mod)[13])

augment(gam_mod) %>% 
  three_metrics(price, .fitted)

(gam_test %>% 
  mutate(predict = predict(gam_mod, gam_test)) %>% 
  ggplot(aes(price, predict, color = type_mod)) + geom_point(alpha = 0.3) +
  geom_abline()) /
(gam_test %>% 
  mutate(predict = predict(gam_mod, gam_test),
         resid = price - predict) %>% 
  ggplot(aes(predict, resid, color = type_mod)) + geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0)) + plot_layout(guides = "collect")

k.check(gam_mod)
```

I would correct the 'k' value for the bath and lon/lat variables, but it took too long for my computer to run. So, we will leave it like this!

And if you are wondering, its metrics did improve.



```{r}
all_metrics_rf %>% 
  bind_rows(augment(gam_mod) %>% 
    three_metrics(price, .fitted) %>% mutate(model = "5")) %>% 
  arrange(desc(.metric), -.estimate)

all_metrics_rf %>% 
  arrange(desc(.metric), -.estimate) %>% 
  bind_rows(augment(gam_mod) %>% 
  three_metrics(price, .fitted) %>% 
    mutate(model = "5")) %>% 
  ggplot(aes(.estimate, .metric, fill = fct_reorder(model, .estimate, max, .desc = TRUE))) +
  geom_col(position = "dodge") + 
  labs(title = "All 5 Models", 
       subtitle = "Base R lm (Brownish-Yellow), TM lm (Green), TM no tax lm (Blue),
Random Forrest (Purple), Gam (Red)") +
  theme(legend.position = "none")
```

The GAM Model outperforms all other models. It has less RMSE and MAE, as well as a higher R^2

```{r eval=FALSE, include=FALSE}
world <- ne_countries(scale = "medium", returnclass = "sf")

range(house$lon, na.rm = TRUE)
range(house$lat, na.rm = TRUE)

ggplot(world) + geom_sf() +
  coord_sf(
    xlim = c(-74.35, -73.6), 
    ylim = c(min(house$lat, na.rm = TRUE), 40.95), expand = FALSE) + 
  geom_point(data = house %>% filter(!is.na(price)) %>% mutate(price = log(price)), 
             aes(lon, lat, color = price, alpha = 0.3)) +
  scale_color_viridis_c()
```

Because of the lack of precision in longitude/latitude variables, the points on the map are slightly off.


```{r eval=FALSE, include=FALSE}
house %>% 
  filter(!is.na(price), between(lon, -75, -73), between(lat, 40, 41)) %>% 
  select(price, lon, lat) %>% 
  pivot_longer(-price) %>% 
  ggplot(aes(value, log(price))) + geom_point() + geom_smooth(formula = y ~ ns(x, 5)) +
  facet_wrap(~name, scales = "free")
```


